{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "# from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "# from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOR NORMAL IMAGES\n",
    "# positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_positive\\\\'\n",
    "# negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR NORMAL W/AUG IMAGES\n",
    "positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\1200aug_equalized_sampled_positive\\\\'\n",
    "negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\1200aug_equalized_sampled_negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOR MASKED IMAGES\n",
    "# positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\masked_images\\\\positive\\\\'\n",
    "# negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\masked_images\\\\negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data\\\\working\\\\train')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/train/positive')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test/positive')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/train/negative')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_len = int(np.floor(len(os.listdir(positive_path))*0.8))\n",
    "positive_len = len(os.listdir(positive_path))\n",
    "\n",
    "negative_train_len = int(np.floor(len(os.listdir(negative_path))*0.8))\n",
    "negative_len = len(os.listdir(negative_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive'):\n",
    "    os.remove(file.path)\n",
    "for trainimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive')\n",
    "    \n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative'):\n",
    "    os.remove(file.path)\n",
    "for trainimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative')\n",
    "\n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/positive'):\n",
    "    os.remove(file.path)\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len, positive_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/positive')\n",
    "\n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/negative'):\n",
    "    os.remove(file.path)\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len, negative_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "    \n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = {\n",
    "    'train': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/train', data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/val', data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/test', data_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(data_images['train'], batch_size=32, shuffle=True, num_workers=0),\n",
    "    'validation': torch.utils.data.DataLoader(data_images['validation'], batch_size=32,shuffle=True,num_workers=0),\n",
    "    'test': torch.utils.data.DataLoader(data_images['test'], batch_size=32,shuffle=True,num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 0\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(device_id)\n",
    "# print(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arnav/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.aux_logits=False\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 3)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trained_model(model, criterion, optimizer, epochs):\n",
    "#     best_acc = 0.0\n",
    "#     best_precision = 0.0\n",
    "#     best_recall = 0.0\n",
    "#     best_f1 = 0.0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         print('Epoch:', str(epoch+1) + '/' + str(epochs))\n",
    "#         print('-'*10)\n",
    "        \n",
    "#         for phase in ['train', 'validation']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train() #this trains the model\n",
    "#             else:\n",
    "#                 model.eval() #this evaluates the model\n",
    "\n",
    "#             running_loss, running_corrects = 0.0, 0 \n",
    "\n",
    "#             iteration_count=0\n",
    "#             total_precision=0\n",
    "#             total_recall=0\n",
    "#             total_f1=0\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device) #convert inputs to cpu or cuda\n",
    "#                 labels = labels.to(device) #convert labels to cpu or cuda\n",
    "\n",
    "                \n",
    "#                 # inputs = inputs.logits\n",
    "#                 outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#                 print('This is OUTPUT')\n",
    "#                 print(outputs)\n",
    "#                 # outputs = outputs.logits\n",
    "#                 loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "\n",
    "#                 if phase == 'train':\n",
    "#                     optimizer.zero_grad() #sets gradients to zero\n",
    "#                     loss.backward() #computes sum of gradients\n",
    "#                     optimizer.step() #preforms an optimization step\n",
    "\n",
    "#                 _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "#                 running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "#                 running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "#                 iteration_count+=1\n",
    "#                 precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 total_precision+=precision_it\n",
    "#                 total_recall+=recall_it\n",
    "#                 total_f1+=f1_it\n",
    "\n",
    "#             epoch_loss = running_loss / len(data_images[phase]) #this is the epoch loss\n",
    "#             epoch_accuracy = running_corrects.double() / len(data_images[phase]) #this is the epoch accuracy\n",
    "#             epoch_precision=total_precision/iteration_count\n",
    "#             epoch_recall=total_recall/iteration_count\n",
    "#             epoch_f1=total_f1/iteration_count\n",
    "\n",
    "#             if phase == 'validation' and epoch_accuracy > best_acc:\n",
    "#                 best_acc = epoch_accuracy\n",
    "#                 best_precision = epoch_precision\n",
    "#                 best_recall = epoch_recall\n",
    "#                 best_f1 = epoch_f1\n",
    "\n",
    "#             print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "#             phase, epoch_loss, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1))\n",
    "#             # print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n",
    "\n",
    "\n",
    "#     print('Best val Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_model(model, criterion, optimizer, epochs):\n",
    "    best_acc = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch:', str(epoch+1) + '/' + str(epochs))\n",
    "        print('-'*10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train() #this trains the model\n",
    "            else:\n",
    "                model.eval() #this evaluates the model\n",
    "\n",
    "            running_loss, running_corrects = 0.0, 0 \n",
    "\n",
    "            iteration_count=0\n",
    "            total_precision=0\n",
    "            total_recall=0\n",
    "            total_f1=0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device) #convert inputs to cpu or cuda\n",
    "                labels = labels.to(device) #convert labels to cpu or cuda\n",
    "\n",
    "                \n",
    "                # inputs = inputs.logits\n",
    "                outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "                # print('This is OUTPUT')\n",
    "                # print(outputs)\n",
    "                # outputs = outputs.logits\n",
    "                loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad() #sets gradients to zero\n",
    "                    loss.backward() #computes sum of gradients\n",
    "                    optimizer.step() #preforms an optimization step\n",
    "\n",
    "                _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "                running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "                running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "                iteration_count+=1\n",
    "                precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                total_precision+=precision_it\n",
    "                total_recall+=recall_it\n",
    "                total_f1+=f1_it\n",
    "\n",
    "            epoch_loss = running_loss / len(data_images[phase]) #this is the epoch loss\n",
    "            epoch_accuracy = running_corrects.double() / len(data_images[phase]) #this is the epoch accuracy\n",
    "            epoch_precision=total_precision/iteration_count\n",
    "            epoch_recall=total_recall/iteration_count\n",
    "            epoch_f1=total_f1/iteration_count\n",
    "\n",
    "            if phase == 'test' and epoch_accuracy > best_acc:\n",
    "                best_acc = epoch_accuracy\n",
    "                best_precision = epoch_precision\n",
    "                best_recall = epoch_recall\n",
    "                best_f1 = epoch_f1\n",
    "\n",
    "            print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "            phase, epoch_loss, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1))\n",
    "            # print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n",
    "\n",
    "\n",
    "    print('Best test Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.396 Acc: 0.823 Prec: 0.850 Recall: 0.823 F1 0.817\n",
      "test Loss: 0.198 Acc: 0.928 Prec: 0.940 Recall: 0.931 F1 0.931\n",
      "Epoch: 2/30\n",
      "----------\n",
      "train Loss: 0.294 Acc: 0.878 Prec: 0.896 Recall: 0.878 F1 0.878\n",
      "test Loss: 0.180 Acc: 0.936 Prec: 0.949 Recall: 0.938 F1 0.938\n",
      "Epoch: 3/30\n",
      "----------\n",
      "train Loss: 0.274 Acc: 0.884 Prec: 0.896 Recall: 0.884 F1 0.884\n",
      "test Loss: 0.167 Acc: 0.941 Prec: 0.953 Recall: 0.943 F1 0.943\n",
      "Epoch: 4/30\n",
      "----------\n",
      "train Loss: 0.267 Acc: 0.888 Prec: 0.901 Recall: 0.888 F1 0.888\n",
      "test Loss: 0.128 Acc: 0.961 Prec: 0.964 Recall: 0.960 F1 0.960\n",
      "Epoch: 5/30\n",
      "----------\n",
      "train Loss: 0.268 Acc: 0.888 Prec: 0.905 Recall: 0.888 F1 0.888\n",
      "test Loss: 0.163 Acc: 0.934 Prec: 0.944 Recall: 0.936 F1 0.936\n",
      "Epoch: 6/30\n",
      "----------\n",
      "train Loss: 0.270 Acc: 0.889 Prec: 0.904 Recall: 0.889 F1 0.889\n",
      "test Loss: 0.164 Acc: 0.943 Prec: 0.953 Recall: 0.944 F1 0.945\n",
      "Epoch: 7/30\n",
      "----------\n",
      "train Loss: 0.266 Acc: 0.891 Prec: 0.905 Recall: 0.891 F1 0.891\n",
      "test Loss: 0.171 Acc: 0.939 Prec: 0.950 Recall: 0.939 F1 0.940\n",
      "Epoch: 8/30\n",
      "----------\n",
      "train Loss: 0.260 Acc: 0.897 Prec: 0.912 Recall: 0.897 F1 0.897\n",
      "test Loss: 0.136 Acc: 0.957 Prec: 0.962 Recall: 0.956 F1 0.957\n",
      "Epoch: 9/30\n",
      "----------\n",
      "train Loss: 0.252 Acc: 0.894 Prec: 0.907 Recall: 0.894 F1 0.895\n",
      "test Loss: 0.158 Acc: 0.941 Prec: 0.949 Recall: 0.939 F1 0.940\n",
      "Epoch: 10/30\n",
      "----------\n",
      "train Loss: 0.238 Acc: 0.904 Prec: 0.914 Recall: 0.904 F1 0.904\n",
      "test Loss: 0.138 Acc: 0.957 Prec: 0.960 Recall: 0.956 F1 0.957\n",
      "Epoch: 11/30\n",
      "----------\n",
      "train Loss: 0.237 Acc: 0.903 Prec: 0.914 Recall: 0.903 F1 0.903\n",
      "test Loss: 0.187 Acc: 0.934 Prec: 0.945 Recall: 0.934 F1 0.934\n",
      "Epoch: 12/30\n",
      "----------\n",
      "train Loss: 0.248 Acc: 0.898 Prec: 0.909 Recall: 0.898 F1 0.898\n",
      "test Loss: 0.212 Acc: 0.911 Prec: 0.929 Recall: 0.909 F1 0.910\n",
      "Epoch: 13/30\n",
      "----------\n",
      "train Loss: 0.236 Acc: 0.902 Prec: 0.913 Recall: 0.902 F1 0.902\n",
      "test Loss: 0.133 Acc: 0.959 Prec: 0.963 Recall: 0.958 F1 0.958\n",
      "Epoch: 14/30\n",
      "----------\n",
      "train Loss: 0.237 Acc: 0.906 Prec: 0.917 Recall: 0.906 F1 0.907\n",
      "test Loss: 0.149 Acc: 0.953 Prec: 0.959 Recall: 0.953 F1 0.954\n",
      "Epoch: 15/30\n",
      "----------\n",
      "train Loss: 0.228 Acc: 0.907 Prec: 0.916 Recall: 0.907 F1 0.907\n",
      "test Loss: 0.123 Acc: 0.966 Prec: 0.968 Recall: 0.967 F1 0.967\n",
      "Epoch: 16/30\n",
      "----------\n",
      "train Loss: 0.234 Acc: 0.904 Prec: 0.916 Recall: 0.904 F1 0.905\n",
      "test Loss: 0.118 Acc: 0.968 Prec: 0.971 Recall: 0.969 F1 0.969\n",
      "Epoch: 17/30\n",
      "----------\n",
      "train Loss: 0.231 Acc: 0.904 Prec: 0.916 Recall: 0.904 F1 0.905\n",
      "test Loss: 0.130 Acc: 0.961 Prec: 0.963 Recall: 0.960 F1 0.960\n",
      "Epoch: 18/30\n",
      "----------\n",
      "train Loss: 0.231 Acc: 0.905 Prec: 0.918 Recall: 0.905 F1 0.906\n",
      "test Loss: 0.195 Acc: 0.928 Prec: 0.942 Recall: 0.929 F1 0.929\n",
      "Epoch: 19/30\n",
      "----------\n",
      "train Loss: 0.216 Acc: 0.913 Prec: 0.923 Recall: 0.913 F1 0.913\n",
      "test Loss: 0.193 Acc: 0.927 Prec: 0.939 Recall: 0.927 F1 0.928\n",
      "Epoch: 20/30\n",
      "----------\n",
      "train Loss: 0.214 Acc: 0.912 Prec: 0.922 Recall: 0.912 F1 0.913\n",
      "test Loss: 0.106 Acc: 0.973 Prec: 0.974 Recall: 0.972 F1 0.972\n",
      "Epoch: 21/30\n",
      "----------\n",
      "train Loss: 0.211 Acc: 0.911 Prec: 0.923 Recall: 0.911 F1 0.912\n",
      "test Loss: 0.169 Acc: 0.928 Prec: 0.943 Recall: 0.929 F1 0.929\n",
      "Epoch: 22/30\n",
      "----------\n",
      "train Loss: 0.225 Acc: 0.910 Prec: 0.922 Recall: 0.910 F1 0.911\n",
      "test Loss: 0.168 Acc: 0.943 Prec: 0.955 Recall: 0.944 F1 0.945\n",
      "Epoch: 23/30\n",
      "----------\n",
      "train Loss: 0.216 Acc: 0.913 Prec: 0.924 Recall: 0.913 F1 0.914\n",
      "test Loss: 0.134 Acc: 0.962 Prec: 0.966 Recall: 0.960 F1 0.960\n",
      "Epoch: 24/30\n",
      "----------\n",
      "train Loss: 0.198 Acc: 0.921 Prec: 0.929 Recall: 0.921 F1 0.921\n",
      "test Loss: 0.112 Acc: 0.968 Prec: 0.968 Recall: 0.965 F1 0.965\n",
      "Epoch: 25/30\n",
      "----------\n",
      "train Loss: 0.194 Acc: 0.920 Prec: 0.929 Recall: 0.920 F1 0.920\n",
      "test Loss: 0.119 Acc: 0.957 Prec: 0.954 Recall: 0.950 F1 0.950\n",
      "Epoch: 26/30\n",
      "----------\n",
      "train Loss: 0.208 Acc: 0.917 Prec: 0.926 Recall: 0.917 F1 0.917\n",
      "test Loss: 0.101 Acc: 0.975 Prec: 0.976 Recall: 0.974 F1 0.974\n",
      "Epoch: 27/30\n",
      "----------\n",
      "train Loss: 0.200 Acc: 0.923 Prec: 0.930 Recall: 0.923 F1 0.923\n",
      "test Loss: 0.129 Acc: 0.968 Prec: 0.970 Recall: 0.969 F1 0.969\n",
      "Epoch: 28/30\n",
      "----------\n",
      "train Loss: 0.193 Acc: 0.922 Prec: 0.930 Recall: 0.922 F1 0.922\n",
      "test Loss: 0.128 Acc: 0.970 Prec: 0.974 Recall: 0.970 F1 0.971\n",
      "Epoch: 29/30\n",
      "----------\n",
      "train Loss: 0.187 Acc: 0.929 Prec: 0.937 Recall: 0.929 F1 0.929\n",
      "test Loss: 0.110 Acc: 0.975 Prec: 0.977 Recall: 0.976 F1 0.976\n",
      "Epoch: 30/30\n",
      "----------\n",
      "train Loss: 0.196 Acc: 0.918 Prec: 0.928 Recall: 0.918 F1 0.919\n",
      "test Loss: 0.111 Acc: 0.975 Prec: 0.977 Recall: 0.974 F1 0.974\n",
      "Best test Acc: 0.975, Best Precision: 0.976, Best Recall: 0.974, Best F1: 0.974\n"
     ]
    }
   ],
   "source": [
    "model = trained_model(model, criterion, optimizer, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_weights/working/models/weights.h5') #save the model's weights\n",
    "# test_model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=False)\n",
    "\n",
    "# test_model.fc = nn.Sequential(\n",
    "#     nn.Linear(2048, 64),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(64, 3)\n",
    "# ).to(torch.device(\"cuda:0\"))\n",
    "\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_weights/working/models/weights.h5')) #load the model's weights\n",
    "# test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model_func(model):\n",
    "    \n",
    "#     num_correct = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()\n",
    "\n",
    "\n",
    "#     # best_acc = 0.0\n",
    "#     # best_precision = 0.0\n",
    "#     # best_recall = 0.0\n",
    "#     # best_f1 = 0.0\n",
    "\n",
    "#     # running_loss, running_corrects = 0.0, 0 \n",
    "#     # iteration_count=0\n",
    "#     # total_precision=0\n",
    "#     # total_recall=0\n",
    "#     # total_f1=0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in dataloaders['test']:\n",
    "\n",
    "\n",
    "\n",
    "#             inputs = inputs.to(torch.device(\"cuda:0\")) #convert inputs to cpu or cuda\n",
    "#             labels = labels.to(torch.device(\"cuda:0\")) #convert labels to cpu or cuda\n",
    "\n",
    "#             # inputs = inputs.logits\n",
    "#             outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#             # outputs = outputs.logits\n",
    "#             # loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "\n",
    "#             # scores = model(inputs)\n",
    "#             # _, predictions = scores.max(1)\n",
    "#             _, predictions = torch.max(outputs, 1)\n",
    "#             num_correct += (predictions == labels).sum()\n",
    "#             num_samples += predictions.size(0)\n",
    "\n",
    "#         print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    \n",
    "#     model.train()\n",
    "#             # _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "#             # running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "#             # running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "#             # iteration_count+=1\n",
    "#             # precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#             # recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#             # f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#             # total_precision+=precision_it\n",
    "#             # total_recall+=recall_it\n",
    "#             # total_f1+=f1_it\n",
    "\n",
    "#     # epoch_loss = running_loss / len(data_images['test']) #this is the epoch loss\n",
    "#     # epoch_accuracy = running_corrects.double() / len(data_images['test']) #this is the epoch accuracy\n",
    "#     # epoch_precision=total_precision/iteration_count\n",
    "#     # epoch_recall=total_recall/iteration_count\n",
    "#     # epoch_f1=total_f1/iteration_count\n",
    "\n",
    "#     # if epoch_accuracy > best_acc:\n",
    "#     #     best_acc = epoch_accuracy\n",
    "#     #     best_precision = epoch_precision\n",
    "#     #     best_recall = epoch_recall\n",
    "#     #     best_f1 = epoch_f1\n",
    "\n",
    "#     # print('Test Loss: {:.3f}, Test Acc: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1: {:.3f}'.format(epoch_loss, best_acc, best_precision, best_recall, best_f1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model_func(model):\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     phase = 'test'\n",
    "    \n",
    "#     running_loss, running_corrects = 0.0, 0 \n",
    "\n",
    "#     iteration_count=0\n",
    "#     total_precision=0\n",
    "#     total_recall=0\n",
    "#     total_f1=0\n",
    "#     for inputs, labels in dataloaders[phase]:\n",
    "#         inputs = inputs.to('cpu') #convert inputs to cpu or cuda\n",
    "#         labels = labels.to('cpu') #convert labels to cpu or cuda\n",
    "#         # print('This is INPUT')\n",
    "#         # print(inputs)\n",
    "#         # print('This is LABELS')\n",
    "#         # print(labels)\n",
    "\n",
    "\n",
    "        \n",
    "#         # inputs = inputs.logits\n",
    "#         outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#         # print('This is OUTPUT')\n",
    "#         # print(outputs)\n",
    "#         # outputs = outputs.logits\n",
    "#         loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "\n",
    "#         _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "#         running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "#         running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "#         iteration_count+=1\n",
    "#         precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#         recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#         f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#         total_precision+=precision_it\n",
    "#         total_recall+=recall_it\n",
    "#         total_f1+=f1_it\n",
    "\n",
    "\n",
    "#         epoch_loss = running_loss / len(data_images[phase]) #this is the epoch loss\n",
    "#         epoch_accuracy = running_corrects.double() / len(data_images[phase]) #this is the epoch accuracy\n",
    "#         epoch_precision=total_precision/iteration_count\n",
    "#         epoch_recall=total_recall/iteration_count\n",
    "#         epoch_f1=total_f1/iteration_count\n",
    "\n",
    "#         if phase == 'validation' and epoch_accuracy > best_acc:\n",
    "#             best_acc = epoch_accuracy\n",
    "#             best_precision = epoch_precision\n",
    "#             best_recall = epoch_recall\n",
    "#             best_f1 = epoch_f1\n",
    "\n",
    "#         print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "#         phase, epoch_loss, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1))\n",
    "#         # print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n",
    "\n",
    "\n",
    "#     print('Best val Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GPUtil import showUtilization as gpu_usage\n",
    "# gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model_func(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9a49f1d600a10354e362afbc6f477ed4542a914b64ffa3b858051b01965c25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
