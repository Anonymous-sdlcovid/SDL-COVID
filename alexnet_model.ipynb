{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOR NORMAL IMAGES\n",
    "# positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_positive\\\\'\n",
    "# negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR NORMAL W/AUG IMAGES\n",
    "positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\1200aug_equalized_sampled_positive\\\\'\n",
    "negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\1200aug_equalized_sampled_negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOR MASKED IMAGES\n",
    "# positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\masked_images\\\\positive\\\\'\n",
    "# negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\masked_images\\\\negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model\\\\working\\\\train')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/test')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/test/positive')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/test/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_len = int(np.floor(len(os.listdir(positive_path))*0.8))\n",
    "positive_len = len(os.listdir(positive_path))\n",
    "\n",
    "negative_train_len = int(np.floor(len(os.listdir(negative_path))*0.8))\n",
    "negative_len = len(os.listdir(negative_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive'):\n",
    "    os.remove(file.path)\n",
    "for trainimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive')\n",
    "    \n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative'):\n",
    "    os.remove(file.path)\n",
    "for trainimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative')\n",
    "\n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/positive'):\n",
    "    os.remove(file.path)\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len, positive_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/positive')\n",
    "\n",
    "for file in os.scandir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/negative'):\n",
    "    os.remove(file.path)\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len, negative_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/val/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        # transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.functional.equalize(),\n",
    "        normalizer\n",
    "    ]),\n",
    "    \n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = {\n",
    "    'train': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/train', data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/val', data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/test', data_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(data_images['train'], batch_size=32, shuffle=True, num_workers=0),\n",
    "    'validation': torch.utils.data.DataLoader(data_images['validation'], batch_size=32,shuffle=True,num_workers=0),\n",
    "    'test': torch.utils.data.DataLoader(data_images['test'], batch_size=32,shuffle=True,num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 0\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(device_id)\n",
    "# print(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.cuda.memory.empty_cache() -> None>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arnav/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 3)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trained_model(model, criterion, optimizer, epochs):\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         print('Epoch:', str(epoch+1) + '/' + str(epochs))\n",
    "#         print('-'*10)\n",
    "        \n",
    "#         for phase in ['train', 'validation']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train() #this trains the model\n",
    "#             else:\n",
    "#                 model.eval() #this evaluates the model\n",
    "\n",
    "#             running_loss, running_corrects = 0.0, 0 \n",
    "\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device) #convert inputs to cpu or cuda\n",
    "#                 labels = labels.to(device) #convert labels to cpu or cuda\n",
    "\n",
    "#                 outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#                 loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "#                 # loss.requires_grad = True\n",
    "\n",
    "\n",
    "#                 if phase == 'train':\n",
    "#                     optimizer.zero_grad() #sets gradients to zero\n",
    "#                     outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#                     loss.backward() #computes sum of gradients\n",
    "#                     optimizer.step() #preforms an optimization step\n",
    "\n",
    "#                 _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "#                 running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "#                 running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "#             epoch_loss = running_loss / len(data_images[phase]) #this is the epoch loss\n",
    "#             epoch_accuracy = running_corrects.double() / len(data_images[phase]) #this is the epoch accuracy\n",
    "\n",
    "#             print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "# import pytorchtools\n",
    "# from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    flag = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if flag == 1:\n",
    "            break\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            iteration_count=0\n",
    "            total_precision=0\n",
    "            total_recall=0\n",
    "            total_f1=0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                iteration_count+=1\n",
    "                precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                total_precision+=precision_it\n",
    "                total_recall+=recall_it\n",
    "                total_f1+=f1_it\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(data_images[phase])\n",
    "            epoch_acc = running_corrects.double() / len(data_images[phase])\n",
    "            epoch_precision=total_precision/iteration_count\n",
    "            epoch_recall=total_recall/iteration_count\n",
    "            epoch_f1=total_f1/iteration_count\n",
    "\n",
    "            print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model and implement early stopping to prevent overfitting\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_precision = epoch_precision\n",
    "                best_recall = epoch_recall\n",
    "                best_f1 = epoch_f1\n",
    "                es = 0\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            elif phase == 'test':\n",
    "                es += 1\n",
    "                print(\"EarlyStopping counter {} of 3\".format(es))\n",
    "\n",
    "                if es > 300:\n",
    "                    print('Early stopping with best_acc: {:4f} and test_acc for this epoch: {:.4f}'.format(best_acc,epoch_acc))\n",
    "                    flag = 1\n",
    "                \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = trained_model(model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.909 Acc: 0.633 Prec: 0.631 Recall: 0.633 F1 0.601\n",
      "test Loss: 0.520 Acc: 0.755 Prec: 0.789 Recall: 0.750 F1 0.725\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "train Loss: 0.527 Acc: 0.742 Prec: 0.783 Recall: 0.742 F1 0.730\n",
      "test Loss: 0.665 Acc: 0.541 Prec: 0.792 Recall: 0.538 F1 0.486\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "train Loss: 0.479 Acc: 0.782 Prec: 0.811 Recall: 0.782 F1 0.776\n",
      "test Loss: 0.612 Acc: 0.790 Prec: 0.815 Recall: 0.792 F1 0.793\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "train Loss: 0.329 Acc: 0.866 Prec: 0.877 Recall: 0.866 F1 0.865\n",
      "test Loss: 0.714 Acc: 0.574 Prec: 0.771 Recall: 0.570 F1 0.523\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "train Loss: 0.329 Acc: 0.867 Prec: 0.886 Recall: 0.867 F1 0.864\n",
      "test Loss: 0.439 Acc: 0.807 Prec: 0.831 Recall: 0.809 F1 0.811\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "train Loss: 0.275 Acc: 0.886 Prec: 0.900 Recall: 0.886 F1 0.885\n",
      "test Loss: 0.649 Acc: 0.654 Prec: 0.788 Recall: 0.660 F1 0.652\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "train Loss: 0.290 Acc: 0.882 Prec: 0.897 Recall: 0.882 F1 0.882\n",
      "test Loss: 0.415 Acc: 0.836 Prec: 0.877 Recall: 0.832 F1 0.839\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "train Loss: 0.138 Acc: 0.950 Prec: 0.953 Recall: 0.950 F1 0.950\n",
      "test Loss: 0.389 Acc: 0.842 Prec: 0.876 Recall: 0.838 F1 0.840\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "train Loss: 0.102 Acc: 0.961 Prec: 0.963 Recall: 0.961 F1 0.961\n",
      "test Loss: 0.365 Acc: 0.847 Prec: 0.879 Recall: 0.844 F1 0.845\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "train Loss: 0.083 Acc: 0.969 Prec: 0.970 Recall: 0.969 F1 0.969\n",
      "test Loss: 0.298 Acc: 0.883 Prec: 0.904 Recall: 0.886 F1 0.888\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "train Loss: 0.069 Acc: 0.972 Prec: 0.974 Recall: 0.972 F1 0.972\n",
      "test Loss: 0.344 Acc: 0.846 Prec: 0.878 Recall: 0.842 F1 0.846\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "train Loss: 0.059 Acc: 0.979 Prec: 0.981 Recall: 0.979 F1 0.979\n",
      "test Loss: 0.285 Acc: 0.878 Prec: 0.899 Recall: 0.878 F1 0.880\n",
      "EarlyStopping counter 2 of 3\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "train Loss: 0.045 Acc: 0.983 Prec: 0.984 Recall: 0.983 F1 0.983\n",
      "test Loss: 0.293 Acc: 0.873 Prec: 0.895 Recall: 0.872 F1 0.874\n",
      "EarlyStopping counter 3 of 3\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "train Loss: 0.042 Acc: 0.984 Prec: 0.985 Recall: 0.984 F1 0.984\n",
      "test Loss: 0.226 Acc: 0.921 Prec: 0.929 Recall: 0.923 F1 0.923\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "train Loss: 0.029 Acc: 0.989 Prec: 0.990 Recall: 0.989 F1 0.989\n",
      "test Loss: 0.276 Acc: 0.878 Prec: 0.900 Recall: 0.878 F1 0.879\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "train Loss: 0.025 Acc: 0.990 Prec: 0.991 Recall: 0.990 F1 0.990\n",
      "test Loss: 0.278 Acc: 0.878 Prec: 0.901 Recall: 0.882 F1 0.884\n",
      "EarlyStopping counter 2 of 3\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "train Loss: 0.021 Acc: 0.993 Prec: 0.994 Recall: 0.993 F1 0.993\n",
      "test Loss: 0.276 Acc: 0.881 Prec: 0.904 Recall: 0.880 F1 0.883\n",
      "EarlyStopping counter 3 of 3\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "train Loss: 0.017 Acc: 0.994 Prec: 0.994 Recall: 0.994 F1 0.994\n",
      "test Loss: 0.284 Acc: 0.883 Prec: 0.905 Recall: 0.886 F1 0.888\n",
      "EarlyStopping counter 4 of 3\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "train Loss: 0.020 Acc: 0.994 Prec: 0.994 Recall: 0.994 F1 0.994\n",
      "test Loss: 0.309 Acc: 0.875 Prec: 0.900 Recall: 0.870 F1 0.874\n",
      "EarlyStopping counter 5 of 3\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "train Loss: 0.019 Acc: 0.994 Prec: 0.994 Recall: 0.994 F1 0.994\n",
      "test Loss: 0.305 Acc: 0.875 Prec: 0.902 Recall: 0.874 F1 0.877\n",
      "EarlyStopping counter 6 of 3\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "train Loss: 0.015 Acc: 0.995 Prec: 0.995 Recall: 0.995 F1 0.995\n",
      "test Loss: 0.297 Acc: 0.879 Prec: 0.902 Recall: 0.883 F1 0.884\n",
      "EarlyStopping counter 7 of 3\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "train Loss: 0.015 Acc: 0.995 Prec: 0.996 Recall: 0.995 F1 0.995\n",
      "test Loss: 0.297 Acc: 0.881 Prec: 0.902 Recall: 0.876 F1 0.878\n",
      "EarlyStopping counter 8 of 3\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "train Loss: 0.014 Acc: 0.996 Prec: 0.996 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.297 Acc: 0.881 Prec: 0.901 Recall: 0.876 F1 0.879\n",
      "EarlyStopping counter 9 of 3\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "train Loss: 0.013 Acc: 0.996 Prec: 0.996 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.302 Acc: 0.881 Prec: 0.901 Recall: 0.880 F1 0.881\n",
      "EarlyStopping counter 10 of 3\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "train Loss: 0.013 Acc: 0.996 Prec: 0.996 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.303 Acc: 0.881 Prec: 0.899 Recall: 0.872 F1 0.876\n",
      "EarlyStopping counter 11 of 3\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "train Loss: 0.013 Acc: 0.997 Prec: 0.997 Recall: 0.997 F1 0.997\n",
      "test Loss: 0.301 Acc: 0.882 Prec: 0.906 Recall: 0.881 F1 0.883\n",
      "EarlyStopping counter 12 of 3\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "train Loss: 0.015 Acc: 0.996 Prec: 0.996 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.296 Acc: 0.879 Prec: 0.905 Recall: 0.883 F1 0.884\n",
      "EarlyStopping counter 13 of 3\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "train Loss: 0.014 Acc: 0.996 Prec: 0.997 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.297 Acc: 0.882 Prec: 0.905 Recall: 0.885 F1 0.886\n",
      "EarlyStopping counter 14 of 3\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "train Loss: 0.013 Acc: 0.996 Prec: 0.996 Recall: 0.996 F1 0.996\n",
      "test Loss: 0.297 Acc: 0.881 Prec: 0.903 Recall: 0.880 F1 0.882\n",
      "EarlyStopping counter 15 of 3\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "train Loss: 0.016 Acc: 0.993 Prec: 0.994 Recall: 0.993 F1 0.993\n",
      "test Loss: 0.297 Acc: 0.881 Prec: 0.905 Recall: 0.884 F1 0.885\n",
      "EarlyStopping counter 16 of 3\n",
      "\n",
      "Training complete in 15m 39s\n",
      "Best test Acc: 0.921, Best Precision: 0.929, Best Recall: 0.923, Best F1: 0.923\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\alexnet_model_weights/working/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\alexnet_model_weights/working/models/weights.h5') #save the model's weights\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\alexnet_model_weights/working/models/weights.h5')) #load the model's weights"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9a49f1d600a10354e362afbc6f477ed4542a914b64ffa3b858051b01965c25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
