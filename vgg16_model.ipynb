{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_positive\\\\'\n",
    "negative_path = 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_sampled_negative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data\\\\working\\\\train')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/train/positive')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test/positive')\n",
    "\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/train/negative')\n",
    "# os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/test/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_len = int(np.floor(len(os.listdir(positive_path))*0.8))\n",
    "positive_len = len(os.listdir(positive_path))\n",
    "\n",
    "negative_train_len = int(np.floor(len(os.listdir(negative_path))*0.8))\n",
    "negative_len = len(os.listdir(negative_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/positive')\n",
    "    \n",
    "for trainimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len):\n",
    "    shutil.copy(trainimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/train/negative')\n",
    "\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(positive_path, '*.png')), positive_train_len, positive_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/test/positive')\n",
    "\n",
    "for testimg in itertools.islice(glob.iglob(os.path.join(negative_path, '*.png')), negative_train_len, negative_len):\n",
    "    shutil.copy(testimg, 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\equalized_data_model/working/test/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ]),\n",
    "    \n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = {\n",
    "    'train': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/train', data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data/equalized_data_model/working/test', data_transforms['validation'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(data_images['train'], batch_size=8, shuffle=True, num_workers=0),\n",
    "    'validation': torch.utils.data.DataLoader(data_images['validation'], batch_size=8,shuffle=True,num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 0\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(device_id)\n",
    "# print(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arnav/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "model.aux_logits=False\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 3)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trained_model(model, criterion, optimizer, epochs):\n",
    "#     best_acc = 0.0\n",
    "#     best_precision = 0.0\n",
    "#     best_recall = 0.0\n",
    "#     best_f1 = 0.0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         print('Epoch:', str(epoch+1) + '/' + str(epochs))\n",
    "#         print('-'*10)\n",
    "        \n",
    "#         for phase in ['train', 'validation']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train() #this trains the model\n",
    "#             else:\n",
    "#                 model.eval() #this evaluates the model\n",
    "\n",
    "#             running_loss, running_corrects = 0.0, 0 \n",
    "\n",
    "#             iteration_count=0\n",
    "#             total_precision=0\n",
    "#             total_recall=0\n",
    "#             total_f1=0\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device) #convert inputs to cpu or cuda\n",
    "#                 labels = labels.to(device) #convert labels to cpu or cuda\n",
    "\n",
    "                \n",
    "#                 # inputs = inputs.logits\n",
    "#                 with torch.no_grad():\n",
    "#                     outputs = model(inputs) #outputs is inputs being fed to the model\n",
    "#                 # outputs = outputs.logits\n",
    "#                 loss = criterion(outputs, labels) #outputs are fed into the model\n",
    "\n",
    "#                 if phase == 'train':\n",
    "#                     # optimizer.zero_grad() #sets gradients to zero\n",
    "#                     loss.requires_grad=True\n",
    "#                     loss.backward() #computes sum of gradients\n",
    "#                     optimizer.step() #preforms an optimization step\n",
    "\n",
    "#                 _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n",
    "#                 running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n",
    "#                 running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n",
    "\n",
    "#                 iteration_count+=1\n",
    "#                 precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "#                 total_precision+=precision_it\n",
    "#                 total_recall+=recall_it\n",
    "#                 total_f1+=f1_it\n",
    "\n",
    "#             epoch_loss = running_loss / len(data_images[phase]) #this is the epoch loss\n",
    "#             epoch_accuracy = running_corrects.double() / len(data_images[phase]) #this is the epoch accuracy\n",
    "#             epoch_precision=total_precision/iteration_count\n",
    "#             epoch_recall=total_recall/iteration_count\n",
    "#             epoch_f1=total_f1/iteration_count\n",
    "\n",
    "#             if phase == 'validation' and epoch_accuracy > best_acc:\n",
    "#                 best_acc = epoch_accuracy\n",
    "#                 best_precision = epoch_precision\n",
    "#                 best_recall = epoch_recall\n",
    "#                 best_f1 = epoch_f1\n",
    "\n",
    "#             print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "#             phase, epoch_loss, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1))\n",
    "#             # print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n",
    "\n",
    "\n",
    "#     print('Best val Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1 = 0.0\n",
    "    flag = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if flag == 1:\n",
    "            break\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            iteration_count=0\n",
    "            total_precision=0\n",
    "            total_recall=0\n",
    "            total_f1=0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                iteration_count+=1\n",
    "                precision_it= precision_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                recall_it= recall_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                f1_it= f1_score(labels.cpu().numpy(),preds.cpu().numpy(), average='weighted', zero_division=0)\n",
    "                total_precision+=precision_it\n",
    "                total_recall+=recall_it\n",
    "                total_f1+=f1_it\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(data_images[phase])\n",
    "            epoch_acc = running_corrects.double() / len(data_images[phase])\n",
    "            epoch_precision=total_precision/iteration_count\n",
    "            epoch_recall=total_recall/iteration_count\n",
    "            epoch_f1=total_f1/iteration_count\n",
    "\n",
    "            print('{} Loss: {:.3f} Acc: {:.3f} Prec: {:.3f} Recall: {:.3f} F1 {:.3f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model and implement early stopping to prevent overfitting\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_precision = epoch_precision\n",
    "                best_recall = epoch_recall\n",
    "                best_f1 = epoch_f1\n",
    "                es = 0\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            elif phase == 'validation':\n",
    "                es += 1\n",
    "                print(\"EarlyStopping counter {} of 3\".format(es))\n",
    "\n",
    "                if es > 300:\n",
    "                    print('Early stopping with best_acc: {:4f} and val_acc for this epoch: {:.4f}'.format(best_acc,epoch_acc))\n",
    "                    flag = 1\n",
    "                \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.3f}, Best Precision: {:.3f}, Best Recall: {:.3f}, Best F1: {:.3f}'.format(best_acc, best_precision, best_recall, best_f1))\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  542254 KB |  542254 KB |  542254 KB |       0 B  |\\n|       from large pool |  540672 KB |  540672 KB |  540672 KB |       0 B  |\\n|       from small pool |    1582 KB |    1582 KB |    1582 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  542254 KB |  542254 KB |  542254 KB |       0 B  |\\n|       from large pool |  540672 KB |  540672 KB |  540672 KB |       0 B  |\\n|       from small pool |    1582 KB |    1582 KB |    1582 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  546816 KB |  546816 KB |  546816 KB |       0 B  |\\n|       from large pool |  544768 KB |  544768 KB |  544768 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    4562 KB |   20359 KB |   43897 KB |   39335 KB |\\n|       from large pool |    4096 KB |   19328 KB |   41856 KB |   37760 KB |\\n|       from small pool |     466 KB |    2041 KB |    2041 KB |    1575 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      36    |      36    |      36    |       0    |\\n|       from large pool |      12    |      12    |      12    |       0    |\\n|       from small pool |      24    |      24    |      24    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      36    |      36    |      36    |       0    |\\n|       from large pool |      12    |      12    |      12    |       0    |\\n|       from small pool |      24    |      24    |      24    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       7    |       7    |       7    |       0    |\\n|       from large pool |       6    |       6    |       6    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       3    |       3    |       4    |       1    |\\n|       from large pool |       2    |       2    |       3    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.887 Acc: 0.534 Prec: 0.524 Recall: 0.534 F1 0.481\n",
      "validation Loss: 0.705 Acc: 0.400 Prec: 0.192 Recall: 0.402 F1 0.253\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "train Loss: 0.710 Acc: 0.509 Prec: 0.472 Recall: 0.509 F1 0.439\n",
      "validation Loss: 0.717 Acc: 0.400 Prec: 0.182 Recall: 0.399 F1 0.245\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "train Loss: 0.704 Acc: 0.518 Prec: 0.458 Recall: 0.518 F1 0.449\n",
      "validation Loss: 0.699 Acc: 0.400 Prec: 0.191 Recall: 0.400 F1 0.251\n",
      "EarlyStopping counter 2 of 3\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "train Loss: 0.701 Acc: 0.502 Prec: 0.473 Recall: 0.502 F1 0.437\n",
      "validation Loss: 0.679 Acc: 0.600 Prec: 0.400 Recall: 0.602 F1 0.473\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "train Loss: 0.699 Acc: 0.510 Prec: 0.469 Recall: 0.510 F1 0.442\n",
      "validation Loss: 0.682 Acc: 0.600 Prec: 0.391 Recall: 0.599 F1 0.465\n",
      "EarlyStopping counter 1 of 3\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "train Loss: 0.702 Acc: 0.497 Prec: 0.441 Recall: 0.497 F1 0.418\n",
      "validation Loss: 0.684 Acc: 0.600 Prec: 0.386 Recall: 0.599 F1 0.463\n",
      "EarlyStopping counter 2 of 3\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "train Loss: 0.700 Acc: 0.497 Prec: 0.470 Recall: 0.497 F1 0.438\n",
      "validation Loss: 0.688 Acc: 0.600 Prec: 0.385 Recall: 0.599 F1 0.462\n",
      "EarlyStopping counter 3 of 3\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.505 Prec: 0.548 Recall: 0.505 F1 0.479\n",
      "validation Loss: 0.688 Acc: 0.600 Prec: 0.396 Recall: 0.602 F1 0.471\n",
      "EarlyStopping counter 4 of 3\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "train Loss: 0.697 Acc: 0.488 Prec: 0.538 Recall: 0.488 F1 0.477\n",
      "validation Loss: 0.694 Acc: 0.400 Prec: 0.187 Recall: 0.399 F1 0.249\n",
      "EarlyStopping counter 5 of 3\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "train Loss: 0.697 Acc: 0.496 Prec: 0.546 Recall: 0.496 F1 0.482\n",
      "validation Loss: 0.703 Acc: 0.400 Prec: 0.197 Recall: 0.399 F1 0.255\n",
      "EarlyStopping counter 6 of 3\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "train Loss: 0.696 Acc: 0.491 Prec: 0.531 Recall: 0.491 F1 0.467\n",
      "validation Loss: 0.701 Acc: 0.400 Prec: 0.183 Recall: 0.399 F1 0.245\n",
      "EarlyStopping counter 7 of 3\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.500 Prec: 0.539 Recall: 0.500 F1 0.478\n",
      "validation Loss: 0.696 Acc: 0.400 Prec: 0.191 Recall: 0.400 F1 0.251\n",
      "EarlyStopping counter 8 of 3\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.501 Prec: 0.550 Recall: 0.501 F1 0.482\n",
      "validation Loss: 0.700 Acc: 0.400 Prec: 0.188 Recall: 0.401 F1 0.249\n",
      "EarlyStopping counter 9 of 3\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "train Loss: 0.693 Acc: 0.519 Prec: 0.544 Recall: 0.519 F1 0.490\n",
      "validation Loss: 0.691 Acc: 0.600 Prec: 0.391 Recall: 0.600 F1 0.466\n",
      "EarlyStopping counter 10 of 3\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.502 Prec: 0.560 Recall: 0.501 F1 0.501\n",
      "validation Loss: 0.695 Acc: 0.400 Prec: 0.184 Recall: 0.399 F1 0.246\n",
      "EarlyStopping counter 11 of 3\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.501 Prec: 0.545 Recall: 0.501 F1 0.492\n",
      "validation Loss: 0.696 Acc: 0.400 Prec: 0.197 Recall: 0.399 F1 0.257\n",
      "EarlyStopping counter 12 of 3\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.501 Prec: 0.547 Recall: 0.501 F1 0.493\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.179 Recall: 0.401 F1 0.243\n",
      "EarlyStopping counter 13 of 3\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.509 Prec: 0.564 Recall: 0.509 F1 0.495\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.191 Recall: 0.398 F1 0.251\n",
      "EarlyStopping counter 14 of 3\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.500 Prec: 0.562 Recall: 0.500 F1 0.496\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.196 Recall: 0.402 F1 0.254\n",
      "EarlyStopping counter 15 of 3\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "train Loss: 0.693 Acc: 0.505 Prec: 0.562 Recall: 0.505 F1 0.492\n",
      "validation Loss: 0.699 Acc: 0.400 Prec: 0.188 Recall: 0.399 F1 0.249\n",
      "EarlyStopping counter 16 of 3\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "train Loss: 0.697 Acc: 0.480 Prec: 0.521 Recall: 0.480 F1 0.462\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.191 Recall: 0.398 F1 0.251\n",
      "EarlyStopping counter 17 of 3\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "train Loss: 0.693 Acc: 0.507 Prec: 0.552 Recall: 0.507 F1 0.491\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.189 Recall: 0.400 F1 0.250\n",
      "EarlyStopping counter 18 of 3\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.509 Prec: 0.560 Recall: 0.509 F1 0.496\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.191 Recall: 0.399 F1 0.250\n",
      "EarlyStopping counter 19 of 3\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.513 Prec: 0.559 Recall: 0.513 F1 0.501\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.187 Recall: 0.400 F1 0.247\n",
      "EarlyStopping counter 20 of 3\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.511 Prec: 0.562 Recall: 0.511 F1 0.499\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.192 Recall: 0.400 F1 0.253\n",
      "EarlyStopping counter 21 of 3\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.506 Prec: 0.557 Recall: 0.506 F1 0.495\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.187 Recall: 0.400 F1 0.248\n",
      "EarlyStopping counter 22 of 3\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "train Loss: 0.696 Acc: 0.498 Prec: 0.548 Recall: 0.498 F1 0.489\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.195 Recall: 0.401 F1 0.254\n",
      "EarlyStopping counter 23 of 3\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "train Loss: 0.694 Acc: 0.515 Prec: 0.567 Recall: 0.515 F1 0.505\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.190 Recall: 0.399 F1 0.251\n",
      "EarlyStopping counter 24 of 3\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.504 Prec: 0.552 Recall: 0.504 F1 0.489\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.187 Recall: 0.400 F1 0.248\n",
      "EarlyStopping counter 25 of 3\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "train Loss: 0.695 Acc: 0.499 Prec: 0.552 Recall: 0.499 F1 0.486\n",
      "validation Loss: 0.698 Acc: 0.400 Prec: 0.189 Recall: 0.401 F1 0.251\n",
      "EarlyStopping counter 26 of 3\n",
      "\n",
      "Training complete in 62m 4s\n",
      "Best val Acc: 0.600, Best Precision: 0.400, Best Recall: 0.602, Best F1: 0.473\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4052/3164956562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/models'"
     ]
    }
   ],
   "source": [
    "os.mkdir('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\inceptionv3_model_data/working/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\vgg16_model_weights/working/models/weights.h5') #save the model's weights\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\arnav\\\\Documents\\\\Arnav\\\\Research-IITR\\\\CovidX_Github_dataset\\\\data\\\\vgg16_model_weights/working/models/weights.h5')) #load the model's weights"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9a49f1d600a10354e362afbc6f477ed4542a914b64ffa3b858051b01965c25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
